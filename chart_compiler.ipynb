{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chart_compiler.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Authenticating\n",
        "\n",
        "Run the cell below (Imports) to load all functions required for the compilation.\n",
        "\n",
        "You will be prompted by Google to authenticate and allow access to your Google Drive. Follow the instructions."
      ],
      "metadata": {
        "id": "Tato1p4L3RCm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjxR4Eg46LnK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Imports\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import seaborn as sns; sns.set()\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "def get_votes_df(votesheet, finalchar=\"\", **options):\n",
        "\n",
        "  votes = np.array(votesheet.get_all_values())\n",
        "  votes_df = pd.DataFrame(votes[1:,:], columns=votes[0], index=range(1,len(votes[:,0])))\n",
        "\n",
        "  # Replace non-breaking white space\n",
        "  votes_df = votes_df.replace(u'\\u00A0',' ', regex=True)\n",
        "\n",
        "  # Tag unranked votes\n",
        "  for voter in votes_df:\n",
        "    votes_df[voter] = votes_df[voter].mask(votes_df[voter].str.startswith(\"[\"), \"-1. \" + votes_df[voter].astype(str))\n",
        "    \n",
        "    #remove comments after finalchar\n",
        "    if finalchar != \"\":\n",
        "      vvv = votes_df[voter].str.split(\"]\", n=1, expand=True) + \"]\"\n",
        "      votes_df[voter] = vvv[0]\n",
        "      \n",
        "  # Replace non-default delimiters\n",
        "  for sd in options[\"special_delimiters\"]:\n",
        "    votes_df.replace(sd, options[\"default_delimiter\"], regex=True, inplace=True)\n",
        "\n",
        "  # Take care of whitespace inconsistencies\n",
        "  if options[\"vote_type\"] == \"ID\":\n",
        "    votes_df = votes_df.replace(' ','', regex=True).replace('.\\[','. [', regex=True)\n",
        "  return votes_df.mask(votes_df==\"]\", \"0\")\n",
        "\n",
        "def get_vote_matrix(votes_df):\n",
        "\n",
        "  vote_matrix = pd.DataFrame()\n",
        "\n",
        "  for voter in votes_df:\n",
        "    for i, vote in enumerate(votes_df[voter]):\n",
        "      if vote == \"\": break\n",
        "      try: rank, title = vote.split(\". \", 1)\n",
        "      except ValueError: \n",
        "        rank, title = i+1, vote.split(\". \", 1)[-1]\n",
        "      title = title.lstrip()\n",
        "      vote_matrix.loc[title, voter] = rank\n",
        "\n",
        "  vote_matrix.fillna(0,inplace=True)\n",
        "  try:\n",
        "    vote_matrix = vote_matrix.astype(pd.SparseDtype(\"int\", 0))\n",
        "  except ValueError:\n",
        "    for col in vote_matrix:\n",
        "      try:\n",
        "        vote_matrix[col].astype(int)\n",
        "      except ValueError:\n",
        "        print(col, \"failed\")\n",
        "        for row in vote_matrix[col].index:\n",
        "          try:\n",
        "            int(vote_matrix.loc[row,col])\n",
        "          except ValueError:\n",
        "            print(\"    rank\", vote_matrix.loc[row,col], \"failed\")\n",
        "            continue\n",
        "        else:\n",
        "          raise Exception(f\"Check sheet again for: {col}\")\n",
        "      print(col, \"succeeded\")\n",
        "\n",
        "  try: vote_matrix = vote_matrix.drop([\"0\"])\n",
        "  except KeyError: pass\n",
        "  #print('Density:', vote_matrix.sparse.density, '\\nvote_matrix.shape', vote_matrix.shape)\n",
        "  return vote_matrix\n",
        "\n",
        "def get_titles_df(metasheet):\n",
        "\n",
        "  titles_arr = np.array(metasheet.get_all_values())\n",
        "  titles_df = pd.DataFrame(titles_arr[1:,1], index=titles_arr[1:,0], columns=[\"Title\"])\n",
        "  return titles_df\n",
        "\n",
        "def get_meta_df(metasheet):\n",
        "\n",
        "  titles_arr = np.array(metasheet.get_all_values())\n",
        "  display(titles_arr)\n",
        "  multiindex = [np.array(titles_arr[1:,0]),np.array(titles_arr[1:,1])]\n",
        "  meta_df = pd.DataFrame(titles_arr[1:,2:], index=multiindex, columns=titles_arr[0,2:])\n",
        "  meta_df.index.names = [\"ID\",\"Title\"]\n",
        "  return meta_df\n",
        "\n",
        "def get_vote_matrix_titled(vote_matrix, meta_df):\n",
        "\n",
        "  vote_matrix = vote_matrix.sort_index()\n",
        "  meta_df = meta_df.sort_index(level=\"Title\")\n",
        "  v = vote_matrix.index\n",
        "  new_ix = meta_df[meta_df.index.get_level_values(\"Title\").isin(v)].index\n",
        "  \n",
        "  if len(new_ix) != len(v): \n",
        "    meta_df = meta_df.sort_index(level=\"ID\")\n",
        "    new_ix = meta_df[meta_df.index.get_level_values(\"ID\").isin(v)].index\n",
        "\n",
        "  if len(new_ix) != len(v):\n",
        "      a = vote_matrix.index\n",
        "      b = meta_df.index.get_level_values(\"Title\")\n",
        "      if len(set(a).difference(set(b))) > 0: display(set(a).symmetric_difference(set(b)))\n",
        "      dupes = meta_df[b.duplicated(keep=False)]\n",
        "      if len(dupes) > 0: display(dupes)\n",
        "      raise Exception(\"Indices gone wild\")\n",
        "\n",
        "  vote_matrix.index = new_ix\n",
        "\n",
        "  # vote_matrix = vote_matrix.sort_index()\n",
        "\n",
        "  # # Case 1: vote_matrix.index consists of IDs\n",
        "  # meta_df = meta_df.sort_index()\n",
        "\n",
        "  # if np.sum(vote_matrix.index != meta_df.index.get_level_values(\"ID\")) != 0:\n",
        "  #   # Case 2: vote_matrix.index consists of titles\n",
        "  #   meta_df = meta_df.sort_index(level=\"Title\")\n",
        "  #   if np.sum(vote_matrix.index != meta_df.index.get_level_values(\"Title\")) != 0:\n",
        "  #     a = vote_matrix.index\n",
        "  #     b = meta_df.index.get_level_values(\"Title\")\n",
        "  #     if len(set(a).difference(set(b))) > 0:\n",
        "  #       display(set(a).symmetric_difference(set(b)))\n",
        "  #       raise Exception(\"\")\n",
        "\n",
        "  # vote_matrix.index = meta_df.index\n",
        "\n",
        "  return vote_matrix\n",
        "\n",
        "def gaussian(x, mu, sig):\n",
        "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
        "\n",
        "def superellipse(x, n=2, a=1, b=1, size=1):\n",
        "  return b * (size**n - np.abs(x/a)**n)**(1/n)\n",
        "\n",
        "def linear_pop_multiplier(counts, most_votes, pop_weight):\n",
        "\n",
        "  theta = np.linspace(-1/most_votes, 1/most_votes, 201)[pop_weight+100]\n",
        "  b = (1-theta*most_votes)/2\n",
        "  multipliers = theta * counts + b\n",
        "  return 2*multipliers\n",
        "\n",
        "def exp_pop_multiplier(counts, most_votes, pop_weight):\n",
        "\n",
        "  if pop_weight == 0: return np.ones(len(counts))\n",
        "\n",
        "  multipliers = 1 + most_votes * np.exp(-(counts-1)**2 / (2*(pop_weight*most_votes)**2))\n",
        "  multipliers /= 1 + most_votes\n",
        "  return multipliers\n",
        "\n",
        "def elliptical_pop_multiplier(counts, most_votes, pop_weight):\n",
        "\n",
        "  if pop_weight >= 0: # mirror superelipse along vertical axis\n",
        "    counts = counts + 2 * (most_votes//2 - counts) + 1 + most_votes%2\n",
        "  \n",
        "  n = np.linspace(1, 0.1, 101)[np.abs(pop_weight)]\n",
        "  multipliers = superellipse(counts-1, n=n, a=1, b=1/most_votes, size=most_votes) # counts-1 to move superellipse upwards\n",
        "  return 2*multipliers\n",
        "\n",
        "def get_results_df(vote_matrix, Weight, PopWeight, pop_multiplier, partial_rankings, size_dependent=False):\n",
        "\n",
        "  for v in vote_matrix: vote_matrix[v] = vote_matrix[v].mask(vote_matrix[v]<0,partial_rankings[v].loc[\"Avg_Unranked_Rank\"])\n",
        "  list_sizes = partial_rankings.loc[\"Size\"] if size_dependent else max(partial_rankings.loc[\"Size\"])\n",
        "\n",
        "  results = pd.DataFrame(index=vote_matrix.index)\n",
        "  results[\"Votes\"] = vote_matrix.astype(bool).sum(axis=1)\n",
        "  MOST_VOTES = max(results[\"Votes\"])\n",
        "\n",
        "  score_matrix = vote_matrix.mask(vote_matrix>0, superellipse(vote_matrix-1,n=Weight,a=1,b=1,size=list_sizes)) # vm-1 to move superellipse upwards\n",
        "  results[\"Score\"] = score_matrix.sum(axis=1)\n",
        "\n",
        "  if pop_multiplier == \"vote_pop_multiplier\": results[\"Score\"] *= results[\"Votes\"]\n",
        "  else: results[\"Score\"] *= pop_multiplier(results[\"Votes\"], MOST_VOTES, PopWeight)\n",
        "\n",
        "  results[\"Score\"] = results[\"Score\"].round(1)\n",
        "  results[\"Score\"] += 0.00001*results[\"Votes\"] # hacky way of breaking ties by number of votes AND use method=\"min\" for tied votes\n",
        "  results[\"Rank\"] = results[\"Score\"].rank(ascending=False,method='min').astype(int)\n",
        "  results[\"Score\"] = results[\"Score\"].round(1)\n",
        "\n",
        "  return results\n",
        "\n",
        "def get_votes_df_from_vote_matrix(vote_matrix):\n",
        "  all_user_votes = []\n",
        "  for v in vote_matrix: \n",
        "    all_user_votes.append(pd.Series(vote_matrix[v][vote_matrix[v] > 0].sort_values().index.get_level_values(level=\"Title\"), name=v))\n",
        "  return pd.concat(all_user_votes, axis=1)\n",
        "  \n",
        "def get_chart_df(vote_matrix):\n",
        "\n",
        "  # Count votes per title\n",
        "  counts = vote_matrix.astype(bool).sum(axis=1)\n",
        "  cdf = pd.DataFrame(index=vote_matrix.index)\n",
        "  cdf['Votes'] = counts.values\n",
        "  most_votes = max(cdf['Votes'])\n",
        "  max_length = np.max(vote_matrix.values)\n",
        "\n",
        "  # Borda count\n",
        "  results = get_results_df(vote_matrix, Weight=1, PopWeight=0, pop_multiplier=linear_pop_multiplier)\n",
        "\n",
        "  # Unqiue score\n",
        "  results[\"Unique\\nScore\"] = results[\"Score\"].where(results[\"Votes\"]==1,0)\n",
        "  results[\"Unique\\nRank\"] = results[\"Unique\\nScore\"].rank(ascending=False,method='first').astype(int)\n",
        "\n",
        "  # Popular score\n",
        "  results['Popular\\nScore'] = results['Score']*results['Votes']\n",
        "  results[\"Popular\\nRank\"] = results[\"Popular\\nScore\"].rank(ascending=False,method='first').astype(int)\n",
        "\n",
        "  # Gold medals\n",
        "  gold_medals = get_results_df(vote_matrix, Weight=0.1, PopWeight=0, pop_multiplier=linear_pop_multiplier)\n",
        "  gold_medals[\"Score\"] /= max_length\n",
        "  gold_medals.drop(\"Votes\",axis=1, inplace=True)\n",
        "  gold_medals.rename({\"Score\":\"Gold\\nMedals\", \"Rank\":\"Gold\\nRank\"}, axis=1, inplace=True)\n",
        "\n",
        "  # Esoteric score\n",
        "  esoteric_results = get_results_df(vote_matrix, Weight=0.4, PopWeight=-50, pop_multiplier=elliptical_pop_multiplier)\n",
        "  esoteric_results.drop(\"Votes\",axis=1, inplace=True)\n",
        "  esoteric_results.rename({\"Score\":\"Esoteric\\nScore\", \"Rank\":\"Esoteric\\nRank\"}, axis=1, inplace=True)\n",
        "\n",
        "  return pd.concat([results, esoteric_results, gold_medals],axis=1)\n",
        "\n",
        "def get_list_sizes_from_vote_matrix(vote_matrix):\n",
        "  \"\"\"\n",
        "  Needed for size-dependent Borda count\n",
        "  Cannot use all_user_votes because it doesn't contain info on which lists are unranked\n",
        "  \"\"\"\n",
        "  return vote_matrix.astype(bool).sum(axis=0)\n",
        "\n",
        "def get_partial_rankings(vote_matrix, size_dependent=False):\n",
        "  \"\"\"\n",
        "  Counts ballot sizes, number of ranked and unranked items, \n",
        "  avg rank of unranked items (=25.5 for completely unranked list of size 50)\n",
        "  \"\"\"\n",
        "  if size_dependent:\n",
        "    size = vote_matrix.astype(bool).sum(axis=0)\n",
        "  else: \n",
        "    size = pd.Series([max(vote_matrix.max(axis=1)) for _ in range(len(vote_matrix.columns))], index=vote_matrix.columns)\n",
        "\n",
        "  unranked = np.abs(vote_matrix.mask(vote_matrix>0,0).sum(axis=0))\n",
        "  ranked = size - unranked\n",
        "  avg_rank = 1+ranked+(unranked-1)/2\n",
        "  df = pd.DataFrame([size.values,ranked.values,unranked.values,avg_rank.values],index=[\"Size\",\"Ranked\",\"Unranked\",\"Avg_Unranked_Rank\"],columns=size.index)\n",
        "  df.loc[\"Avg_Unranked_Rank\"] = df.loc[\"Avg_Unranked_Rank\"].mask(df.loc[\"Unranked\"]==0,0)\n",
        "  print(\"rounding unranked ballots\")\n",
        "  df.loc[\"Avg_Unranked_Rank\"] = df.loc[\"Avg_Unranked_Rank\"].round(0).astype(int)\n",
        "  return df\n",
        "\n",
        "def sheet_updater(gc, SHEETNAME, verbose=False, **options):\n",
        "\n",
        "  # Load sheets\n",
        "  votesheet = gc.open(SHEETNAME).worksheet('Votes')\n",
        "  metasheet = gc.open(SHEETNAME).worksheet('Titles')\n",
        "\n",
        "  # Get votes df\n",
        "  votes_df = get_votes_df(votesheet,**options)\n",
        "  if verbose: display(votes_df.head())\n",
        "\n",
        "  # Get vote matrix\n",
        "  vote_matrix = get_vote_matrix(votes_df)\n",
        "  if verbose: display(vote_matrix.head())\n",
        "  if verbose: print(\"Vote matrix shape:\", vote_matrix.shape)\n",
        "\n",
        "  # Append titles to vote matrix index\n",
        "  meta_df = get_meta_df(metasheet).sort_index()\n",
        "  #titles_df = get_titles_df(metasheet)\n",
        "  if verbose: display(meta_df.head())\n",
        "  if verbose: print(\"Meta df shape:\", meta_df.shape)\n",
        "\n",
        "  if len(meta_df) != len(vote_matrix):   \n",
        "    if verbose: print(len(meta_df),len(vote_matrix))\n",
        "    print(\"New IDs detected:\\n\")\n",
        "    a=set(vote_matrix.index) - set(meta_df.index.get_level_values(level=options[\"vote_type\"]))\n",
        "    b=set(meta_df.index.get_level_values(level=options[\"vote_type\"])) - set(vote_matrix.index)\n",
        "    print(\"Only in vote sheet:\")\n",
        "    for title in a: print(title)\n",
        "    if verbose: print(\"Lenghts:\", len(a),len(b))\n",
        "    if verbose: print(\"\\n\\n\")\n",
        "    print(\"Only in title sheet:\")\n",
        "    for title in b: print(title[0] if len(b) > 1 else title)\n",
        "    if verbose: display(vote_matrix.loc[a])\n",
        "    if verbose: display(meta_df[meta_df.index.get_level_values(options[\"vote_type\"]).isin(b)])\n",
        "    if len(a) > 0: raise Exception(\"Update tiltes sheet\")\n",
        "    if len(b) > 0: meta_df = meta_df[~meta_df.index.get_level_values(options[\"vote_type\"]).isin(b)]\n",
        "\n",
        "  vote_matrix = get_vote_matrix_titled(vote_matrix, meta_df)\n",
        "  # vote_matrix.to_csv(f\"/content/drive/MyDrive/{SHEETNAME}_vote_matrix.csv\")\n",
        "  # print(\"Saved vote matrix:\", f\"/content/drive/MyDrive/{SHEETNAME}_vote_matrix.csv\")\n",
        "  # display(vote_matrix.head())\n",
        "\n",
        "  # Make the chart df\n",
        "  # cdf = get_chart_df(vote_matrix)\n",
        "\n",
        "  # if update_chartsheet: \n",
        "  #   cdf[\"ID\"] = cdf.index.get_level_values(level=\"ID\")\n",
        "  #   cdf = cdf.sort_values(by=\"ID\")\n",
        "  #   cdf[\"Title\"] = cdf.index.get_level_values(level=\"Title\")\n",
        "  #   cols = [\"Rank\", \"Title\", \"ID\", \"Votes\",\t\"Score\",\t\"Esoteric\\nRank\",\t\"Esoteric\\nScore\", \"Gold\\nRank\", \"Gold\\nMedals\", \"Popular\\nRank\", \"Popular\\nScore\", \"Unique\\nRank\", \"Unique\\nScore\"]\n",
        "  #   cdf = cdf[cols]\n",
        "  #   set_with_dataframe(chartsheet, cdf.sort_values(\"Rank\"), include_index=False)\n",
        "  \n",
        "  return meta_df, vote_matrix\n",
        "  \n",
        "def load_data_from_sheet(**options):\n",
        "\n",
        "  import gspread\n",
        "  from gspread_dataframe import set_with_dataframe\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  #gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "  meta_df, vote_matrix = sheet_updater(gc, **options)\n",
        "\n",
        "  if options[\"remove_original_title\"]:\n",
        "\n",
        "    meta_df.sort_index(level=\"ID\",inplace=True)\n",
        "    vote_matrix.sort_index(level=\"ID\",inplace=True)\n",
        "\n",
        "    cleaned_title = vote_matrix.index.get_level_values(level=\"Title\")\n",
        "    cleaned_title = cleaned_title.where(cleaned_title.str[-1:] != ']', cleaned_title.str[:-1].str.split('[').str[1])\n",
        "    vote_matrix.index.get_level_values(level=\"Title\")\n",
        "    vote_matrix['Title'] = cleaned_title\n",
        "    vote_matrix.index = vote_matrix.index.droplevel(level=\"Title\")\n",
        "    vote_matrix.set_index('Title', append=True, inplace=True)\n",
        "\n",
        "    meta_df.index = vote_matrix.index\n",
        "\n",
        "  nantitles = vote_matrix.index.get_level_values(level=\"Title\").to_numpy() != vote_matrix.index.get_level_values(level=\"Title\").to_numpy()\n",
        "  vote_matrix.index = pd.MultiIndex.from_tuples([(x[0], x[0] if nan else x[1]) for x, nan in zip(vote_matrix.index, nantitles)], names=[\"ID\",\"Title\"])\n",
        "\n",
        "  vote_matrix_all_ranked = vote_matrix.mask(vote_matrix < 0, 25.5)\n",
        "  all_user_votes = get_votes_df_from_vote_matrix(vote_matrix_all_ranked)\n",
        "\n",
        "  partial_rankings = get_partial_rankings(vote_matrix, size_dependent = options[\"size_dependent_borda\"])\n",
        "\n",
        "  if options[\"DEFAULT_RANK_OPTION\"] =='BORDA_RANK':\n",
        "    DEFAULT_RANK = get_results_df(vote_matrix, 1, 0, linear_pop_multiplier, partial_rankings, size_dependent=options[\"size_dependent_borda\"]).sort_values(by=\"Rank\")\n",
        "  else:\n",
        "    DEFAULT_RANK = get_results_df(vote_matrix, 1, 0, \"vote_pop_multiplier\", partial_rankings, size_dependent=options[\"size_dependent_borda\"]).sort_values(by=\"Rank\")\n",
        "\n",
        "  meta_df = meta_df.loc[DEFAULT_RANK.index]\n",
        "\n",
        "  # if query_tmdb:\n",
        "  #   query_tmdb_wrapper(DEFAULT_RANK, **options)\n",
        "  print(\"Compilation succeeded!\")\n",
        "  return vote_matrix, vote_matrix_all_ranked, all_user_votes, meta_df, DEFAULT_RANK"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Enter the sheet name\n",
        "\n",
        "Assuming you have prepared a Google sheet with all the votes according to the [sheet instructions](https://imgur.com/a/CedCgWA), you will now have to enter the name of your spreadsheet in the options below. Then, run the cell.\n",
        "\n",
        "[example sheet](https://docs.google.com/spreadsheets/d/105FAvXZa_E8KBOORGyvdIXhkCpoxqgJJAVn_OxCX_CA/edit?usp=sharing)\n",
        "\n"
      ],
      "metadata": {
        "id": "C-B3rvy8vzqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "options = {}\n",
        "\n",
        "# Enter your sheetname below\n",
        "\n",
        "options[\"SHEETNAME\"] = 'RYM AniChart 4.1'\n",
        "\n",
        "#\"2000s Movies\"\n",
        "\n",
        "## ADVANCED OPTIONS (leave default values)\n",
        "\n",
        "options[\"default_delimiter\"] = \". \"\n",
        "options[\"special_delimiters\"] = [\"\\) \"]\n",
        "options[\"load_from_sheet\"] = True\n",
        "options[\"finalchar\"] = \"]\"\n",
        "options[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK_CLASSIC\"\n",
        "options[\"remove_original_title\"] = True\n",
        "options[\"size_dependent_borda\"] = False\n",
        "options[\"vote_type\"] = \"ID\"\n",
        "# options[\"database_id\"] = \"TMDB_id\"\n",
        "# options[\"link\"] = \"https://www.themoviedb.org/movie/\"\n",
        "# options[\"dataname\"] = 'Film (2010s)'\n",
        "# options[\"vote_matrix_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/2010s%20Movies_vote_matrix.csv\"\n",
        "# options[\"titles_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/2010s%20Movies%20-%20Titles.csv\"\n",
        "# options[\"metacols\"] = ['Release','Runtime','Genres','Language','Cast','Director','Producer','Writer','Director of Photography','Editor','Composer','Sound Designer','Art Direction','Production Design','Costume Design','Makeup Artist']\n",
        "# options[\"type\"] = \"Film\"\n",
        "# options[\"print\"] = \"ID\"\n",
        "\n",
        "\n",
        "if options[\"SHEETNAME\"] == 'RYM AniChart 4.1':\n",
        "  options[\"dataname\"] = 'Anime Series'\n",
        "  options[\"SHEETNAME\"] = 'RYM AniChart 4.1'\n",
        "  options[\"finalchar\"] = \"\"\n",
        "  options[\"database_id\"] = \"AniListID\"\n",
        "  options[\"link\"] = \"https://anilist.co/anime/\"\n",
        "  options[\"remove_original_title\"] = False\n",
        "  options[\"vote_matrix_csv\"] = \"./data/RYM AniChart_ranked_vote_matrix.csv\"\n",
        "  options[\"titles_csv\"] = \"./data/RYM AniChart_metadata.csv\"\n",
        "  options[\"metacols\"] = ['Genres','Studio','Source','Episodes','First Air Date','Last Air Date']\n",
        "  options[\"type\"] = \"Series\"\n",
        "  options[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK\"\n",
        "  options[\"print\"] = \"Title\"\n",
        "  options[\"size_dependent_borda\"] = True\n",
        "  options[\"vote_type\"] = \"Title\""
      ],
      "metadata": {
        "id": "xBHr_obBvjjI"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Compute the results\n",
        "\n",
        "Run the cell below.\n",
        "\n",
        "If you get **Exception: Update titles sheet** (likely when compiling the results for the first time or adding a new voter later), **append** the printed RYM shortcuts to the ID column of the titles sheet. Match the shortcuts with the appropriate titles from RYM and copy them to the titles sheet as well (see also the [sheet instructions](https://imgur.com/a/CedCgWA)).\n",
        "\n",
        "Once the titles sheet has been updated, re-run the cell below.\n",
        "\n",
        "If you get some empty brackets instead of RYM shortcuts in the exception: empty the titles sheet, re-run the cell, copy the newly generated ID list and the matching titles back into the titles sheet, re-run the cell. This is a bug and will be fixed in a future update."
      ],
      "metadata": {
        "id": "_rYw0Bf15AiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vote_matrix, vote_matrix_all_ranked, all_user_votes, meta_df, DEFAULT_RANK = load_data_from_sheet(**options)"
      ],
      "metadata": {
        "id": "xT3HdRkEvSo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Display the results\n",
        "\n",
        "Run the cell below. Then, click on the magic wand on the top right corner of the dataframe to get an interactive dataframe. You can sort the results by clicking on a column name."
      ],
      "metadata": {
        "id": "ZG83DvCA8zAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "DEFAULT_RANK"
      ],
      "metadata": {
        "id": "Ijj5o3g-yu61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below for a RYM printable version:"
      ],
      "metadata": {
        "id": "LLBJgdVwAX-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ID in DEFAULT_RANK.sort_values(by=\"Rank\").index:\n",
        "  votes = int(DEFAULT_RANK.loc[ID]['Votes'])\n",
        "  totalscore = int(DEFAULT_RANK.loc[ID]['Score'])\n",
        "  rawscore = totalscore // votes\n",
        "  print(f\"{DEFAULT_RANK.loc[ID]['Rank']:.0f}. {ID[0]} {votes}*{rawscore}={totalscore}\")"
      ],
      "metadata": {
        "id": "PJron9gO_qj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Most no. 1\n",
        "gold=all_user_votes.iloc[0].value_counts()\n",
        "for i, g in enumerate(gold):\n",
        "  print(gold.index[i], g)"
      ],
      "metadata": {
        "id": "RM1m4zVd4PrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# highest pos without #1\n",
        "\n",
        "DEFAULT_RANK.drop(gold.index,axis=0,level=1)"
      ],
      "metadata": {
        "id": "DDD5ftCX4QkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vote_matrix"
      ],
      "metadata": {
        "id": "3V63OYW5YQfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_votes"
      ],
      "metadata": {
        "id": "m4An7zjIYRGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save as CSV"
      ],
      "metadata": {
        "id": "THPNhRJN-BQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SHEETNAME = options[\"SHEETNAME\"]\n",
        "vote_matrix.to_csv(f\"/content/drive/MyDrive/{SHEETNAME}_vote_matrix.csv\")\n",
        "print(\"Saved vote matrix:\", f\"/content/drive/MyDrive/{SHEETNAME}_vote_matrix.csv\")\n",
        "\n",
        "meta_df.to_csv(f\"/content/drive/MyDrive/{SHEETNAME}_meta_df.csv\")\n",
        "print(\"Saved meta_df:\", f\"/content/drive/MyDrive/{SHEETNAME}_meta_df.csv\")"
      ],
      "metadata": {
        "id": "pjUAxqXd-EAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AniChart Metadata"
      ],
      "metadata": {
        "id": "VSja62xdh9_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://graphql.anilist.co'\n",
        "\n",
        "query = '''\n",
        "query ($id: Int, $page: Int, $perPage: Int, $search: String) {\n",
        "    Page (page: $page, perPage: $perPage) {\n",
        "        pageInfo {\n",
        "            total\n",
        "            currentPage\n",
        "            lastPage\n",
        "            hasNextPage\n",
        "            perPage\n",
        "        }\n",
        "        media (id: $id, search: $search, type: ANIME) {\n",
        "            id\n",
        "            source\n",
        "            genres\n",
        "            episodes\n",
        "            title {\n",
        "                romaji\n",
        "            }\n",
        "\n",
        "\n",
        "            studios {\n",
        "              edges {\n",
        "                id\n",
        "                isMain\n",
        "                node {\n",
        "                  name\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "\n",
        "\n",
        "        }\n",
        "    }\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "_J9PdyabiAgr"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df.head()"
      ],
      "metadata": {
        "id": "9Hem4xX4CVSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query Anilist\n",
        "meta_df['Genres'].astype(object) # to insert lists\n",
        "meta_df = meta_df.replace(np.nan,\"\")\n",
        "\n",
        "def AniQuery(meta_df,variables,title_ix,query=query):\n",
        "    response = requests.post(url, json={'query': query, 'variables': variables})\n",
        "    parsed = json.loads(response.text)\n",
        "    dat = parsed['data']['Page']['media'][0]\n",
        "    #pretty_data = json.dumps(dat, indent=4, sort_keys=True)\n",
        "    #print(pretty_data,'\\n')\n",
        "\n",
        "    meta_df.loc[title_ix,'Source'] = dat['source']\n",
        "    if dat['studios']['edges']:\n",
        "        meta_df.loc[title_ix,'Studio'] = list(filter(lambda x:x[\"isMain\"]==True,dat['studios']['edges']))[0]['node']['name']\n",
        "    meta_df.at[title_ix, 'Genres'] = dat['genres']\n",
        "\n",
        "    meta_df.loc[title_ix, 'AniListID'] = dat['id'] \n",
        "\n",
        "for i, title_ix in enumerate(meta_df.index):\n",
        "    title = title_ix[1]\n",
        "    if i % 50 == 0:\n",
        "        print(i,title)\n",
        "    variables = {'search': title}\n",
        "    \n",
        "    if (meta_df.loc[title_ix, 'Source'] in [np.nan,None, ''] or\n",
        "        meta_df.loc[title_ix, 'Genres'] in [np.nan,None, ''] or\n",
        "        meta_df.loc[title_ix, 'Studio'] in [np.nan,None, ''] or\n",
        "        meta_df.loc[title_ix, 'AniListID'] in [np.nan,None, '']):\n",
        "\n",
        "        try:\n",
        "            if meta_df.loc[title_ix, 'AniListID'] != \"\":\n",
        "              variables = {\"id\": meta_df.loc[title_ix, 'AniListID']}\n",
        "            AniQuery(meta_df,variables,title_ix)\n",
        "        except KeyError:\n",
        "            print('KeyError:',title)\n",
        "            continue\n",
        "        except IndexError:\n",
        "            print(\"IndexError:\", title)\n",
        "            continue\n",
        "        except TypeError:\n",
        "            print(\"TypeError:\", title)\n",
        "            continue         \n",
        "meta_df.head()"
      ],
      "metadata": {
        "id": "3m725C7kCCBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten genres list\n",
        "separator = ', '\n",
        "for title in meta_df.index:\n",
        "    if type(meta_df.loc[title,'Genres']) == list:\n",
        "        meta_df.loc[title,'Genres'] = separator.join(meta_df.loc[title,'Genres'])\n",
        "\n",
        "\n",
        "# Capitalize Source\n",
        "meta_df['Source'] = meta_df['Source'].str.replace('_',' ')\n",
        "meta_df['Source'] = meta_df['Source'].str.title()"
      ],
      "metadata": {
        "id": "g_Whu75NCd94"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query TMDb.org\n",
        "\n",
        "f = open(\"/content/drive/MyDrive/tmdb_api_key.txt\", \"r\")\n",
        "api_key = f.read()[:-1]\n",
        "f.close()\n",
        "\n",
        "for i, title_ix in enumerate(meta_df.index):\n",
        "    title = title_ix[1]\n",
        "    if i % 50 == 0:\n",
        "        print(i,title)\n",
        "    \n",
        "    if (meta_df.loc[title_ix,'Episodes'] in [None, ''] or\n",
        "        meta_df.loc[title_ix,'First Air Date'] in [None, ''] or\n",
        "        meta_df.loc[title_ix,'Last Air Date'] in [None, ''] or \n",
        "        meta_df.loc[title_ix, 'IMGID'] in [None,''] or \n",
        "        meta_df.loc[title_ix, 'TMDbID'] in [None,'']):\n",
        "        \n",
        "        title_id = str(meta_df.loc[title_ix, 'TMDbID'])\n",
        "        \n",
        "        try:\n",
        "            if title_id in [None,'','None']:\n",
        "                \n",
        "                r = requests.get('https://api.themoviedb.org/3/search/tv?api_key='+api_key+'&query='+title)\n",
        "                parsed = json.loads(r.text)  \n",
        "                \n",
        "                # Make sure TMDb genre contains animation (possibly: origin country is JP)\n",
        "                for j, res in enumerate(parsed['results']):\n",
        "                    if 16 in res['genre_ids']: # TMDb genre ID for animation = 16\n",
        "                        title_id = str(res['id'])\n",
        "                        meta_df.loc[title_ix, 'TMDbID'] = title_id\n",
        "                        break\n",
        "\n",
        "                if title_id in [None,'','None']:\n",
        "                    raise NameError('TitleID')\n",
        "\n",
        "        except KeyError:\n",
        "            print('KeyError1:',title)\n",
        "            continue\n",
        "        except IndexError:\n",
        "            print('IndexError1:',title)\n",
        "            continue\n",
        "        except NameError:\n",
        "            print('NameError1',title)\n",
        "            continue     \n",
        "\n",
        "        # Get episodes\n",
        "        r = requests.get('https://api.themoviedb.org/3/tv/'+title_id+'?api_key='+api_key)\n",
        "        parsed = json.loads(r.text)\n",
        "        #pretty_data = json.dumps(parsed, indent=4, sort_keys=True)\n",
        "        #print(pretty_data)\n",
        "        \n",
        "        try:\n",
        "            meta_df.loc[title_ix, 'IMGID'] = parsed['poster_path']\n",
        "            meta_df.loc[title_ix, 'Episodes'] = parsed['number_of_episodes']\n",
        "            meta_df.loc[title_ix, 'First Air Date'] = parsed['first_air_date']\n",
        "            meta_df.loc[title_ix, 'Last Air Date'] = parsed['last_air_date']\n",
        "        except KeyError:\n",
        "            print('KeyError2:',title,title_id)\n",
        "            if title_id in [np.nan]:\n",
        "              print(\"erere\")\n",
        "            print(type(title_id))\n",
        "            continue\n",
        "        except IndexError:\n",
        "            print('IndexError2:',title)\n",
        "            continue\n",
        "        except NameError:\n",
        "            print('NameError2',title)\n",
        "            continue     "
      ],
      "metadata": {
        "id": "swiinNBfD10c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df.to_csv(f\"/content/drive/MyDrive/{SHEETNAME}_meta_df.csv\")\n",
        "print(\"Saved meta_df:\", f\"/content/drive/MyDrive/{SHEETNAME}_meta_df.csv\")"
      ],
      "metadata": {
        "id": "1-5EaVlqG19i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}